{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does not reflect definitive results of our study and is solely for ad hoc exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import read_json\n",
    "data = read_json(\"../../data/annotations.json\")\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = list({line[\"source\"] for user_line in data for line in user_line[\"lines\"]})\n",
    "srcs = random.Random(0).sample(srcs, k=20)\n",
    "\n",
    "src_v_n1 = {line[\"source\"] : line[\"translations\"][\"4\"][\"orig\"] for user_line in data for line in user_line[\"lines\"]}\n",
    "src_v_p1 = {line[\"source\"] : line[\"translations\"][\"1\"][\"orig\"] for user_line in data for line in user_line[\"lines\"]}\n",
    "src_v_p3 = {line[\"source\"] : line[\"translations\"][\"3\"][\"orig\"] for user_line in data for line in user_line[\"lines\"]}\n",
    "src_v_n1_pe = {line[\"source\"]: line[\"translations\"][\"4\"][\"done\"] for user_line in data for line in user_line[\"lines\"]}\n",
    "src_v_p1_pe = {line[\"source\"]: line[\"translations\"][\"1\"][\"done\"] for user_line in data for line in user_line[\"lines\"]}\n",
    "src_v_p3_pe = {line[\"source\"]: line[\"translations\"][\"3\"][\"done\"] for user_line in data for line in user_line[\"lines\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_google = np.array([0.7, 0.8, 0.75, 0.9, 0.85, 0.9, 0.8, 0.95, 0.8, 0.9, 0.5, 0.8, 0.9, 1, 0.9, 1, 0.95, 0.8, 0.8, 0.7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(srcs))\n",
    "\n",
    "\n",
    "tgts_google = \"\"\"\n",
    "\"Utekli se smíchy a já tam jen seděla,\" řekla Amari.\n",
    "Dopis zaslaný rodinám dříve v září, kbleuý je informoval o ztrátě, byl náhodou adresován dětem – spíše než rodičům. Nemocnice se také omluvila rodičům za přehlédnutí zpráv.\n",
    "A Johnsonova slabost dá 27 vůdcům, kteří mu čelí, ještě méně podnětů k vymazání zásadních červených čar, navzdory tvrzení Michaela Govea, britského ministra odpovědného za brexit bez dohody, že se „posouvají“ na pojistce.\n",
    "\"Usoudili jsme, že nejvhodnějším dalším krokem je zapojení donucovacích orgánů. V tuto chvíli je vyšetřování v rukou orgánů činných v trestním řízení a není vhodné, abychom se k podstatě našich zjištění dále vyjadřovali,\" pokračuje prohlášení. .\n",
    "\"Pokusila jsem se spát a moje tělo by se začalo třást, a pak jsem začala šílet a začala jsem brečet,\" řekla Corona ABC-7.\n",
    "Vojenští a obranní vůdci vyjádřili zděšení a odhodlání udělat více pro zvýšení odolnosti jednotek, vyškolit členy služby, jak lépe zvládat stres, a povzbudit vojáky, aby vyhledali pomoc, když ji potřebují. Van Winkle řekl, že armáda také zvažuje zvýšené úsilí o výcvik vojáků v bezpečném skladování střelných zbraní a léků. Řekla, že neexistují žádná konzistentní pravidla nebo předpisy napříč minisbleustvem a službami vyžadujícími zámky na zbraně nebo jiné kontroly střelných zbraní, ale že některé státy nebo základny mají svá vlastní omezení.\n",
    "Rozhodl se však podstoupit test na detektoru lži, aby rozptýlil veškeré spekulace, že to byl on, kdo si poslal tweet, uvedla jeho právnička Megan Kiefer. Žaloba zatím jménem Dunlapa podána nebyla, ale ve svém prohlášení uvedl, že podle WWL-TV jedna přijde.\n",
    "Minulý týden ministr obrany Mark Esper řekl, že na Blízký východ se rozmístí více vojáků jako „obranné“ opatření, které má pomoci chránit před útoky z Íránu.\n",
    "Vypadá to, že teď, když Disney a Sony urovnaly své neshody, dojde k jakémusi návratu Spider-Mana.\n",
    "Normálně monzun v severní Indii začátkem září ustoupí, ale průměrné srážky v tomto měsíci byly o 37 % nad normálem. Pokud bude situace pokračovat i po zbývajících pár dní, bude to podle odborníků z indického meteorologického oddělení poslední ústup monzunu za desítky let.\n",
    "Armáda vidí frustrující trend jako bodec sebevražd\n",
    "Pete Townshend vysvětlil publiku, co se děje: „Obávám se, že to zní, jako by už nemohl...“\n",
    "Zdroje uvedly, že akce byla v souladu s projevem premiéra Narendry Modiho k národu z opevnění Rudé pevnosti, když řekl, že některé černé ovce v daňové správě mohly zneužít své pravomoci a obtěžovat daňové poplatníky, a to buď tím, že se zaměřili na poctivé odhadce nebo vzali nepřiměřené akce za drobná nebo procesní porušení.\n",
    "V mnoha oblastech země stále bezprecedentně prší, posledním je město Pune v západní Indii, kde přívalový déšť ve středu a ve čtvrtek způsobil několik úmrtí a zkázu kvůli zříceným budovám.\n",
    "Seth Dunlap Louisiana: Moderátor rádia WWL, který vyhrožuje žalobou kvůli anti-gay tweetu, poslal tweet sám, tvrdí stanice, podobně jako případ Jussie Smollett\n",
    "„O Undergraduate Awards zuřivě bojují tisíce studentů po celém světě a je to skvělý odraz kvality našich studentů a vzdělání, které zde dostávají, že Dundee je tak silně zastoupeno mezi vítězi cen.\n",
    "Dodal, že USA poskytnou Organizaci pro zákaz chemických zbraní dalších 4,5 milionu dolarů na financování vyšetřování dalších případů podezřelého ze syrského použití chemických zbraní.\n",
    "Když se vrátil, Townsend řekl: \"Opravdu, opravdu mě to mrzí. Roger teď vlastně nemůže mluvit.\"\n",
    "Zatím nepojmenovaný film bude uveden 16. července 2021 a bude produkován společností Disney vlastněnou Marvel Studios a jejím prezidentem Kevinem Feigem, jak uvádí tisková zpráva zaslaná oběma studii.\n",
    "\"Naše čísla se nepohybují správným směrem,\" řekla Elizabeth Van Winkle, ředitelka úřadu pro odolnost sil Pentagonu. Řekla, že většina vojenských sazeb je srovnatelná s civilisty, ale dodala, že \"to je sotva uklidňující.\"\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "assert len(tgts_google) == len(srcs)\n",
    "\n",
    "tgts_cubitt = \"\"\"\n",
    "\"Utekli se smíchem a já tam jen tak seděl,\" řekl Amari.\n",
    "Dopis, který byl počátkem září zaslán rodinám a který je informoval o ztrátě, byl omylem adresován dětem - spíše než rodičům. Nemocnice se také omluvila rodičům za přehlédnutí zpráv.\n",
    "A Johnsonova slabost dá 27 lídrům, kteří před ním stojí, ještě menší motivaci k mazání zásadních červených čar, navzdory tvrzení Michaela Govea, britského ministra zodpovědného za brexit bez dohody, že se \"posouvají\" na druhou kolej.\n",
    "\"Rozhodli jsme se, že nejvhodnějším dalším krokem bude zapojení donucovacích orgánů. V této chvíli je vyšetřování v rukou orgánů činných v trestním řízení a není vhodné, abychom se dále vyjadřovali k podstatě našich zjištění,\" pokračuje prohlášení.\n",
    "\"Snažila jsem se usnout a tělo se mi začalo třást a pak jsem začala vyšilovat a začala jsem brečet,\" řekla Corona televizi ABC-7.\n",
    "Vojenští a obranní vůdci vyjádřili zděšení a odhodlání udělat více pro zvýšení odolnosti sil, trénovat členy služeb, jak lépe zvládat stres a povzbuzovat vojáky, aby hledali pomoc, když ji potřebují. Van Winkle řekl, že armáda také usiluje o zvýšení úsilí při výcviku vojáků v oblasti bezpečného skladování střelných zbraní a léků. Řekla, že na celém oddělení neexistují jednotná pravidla nebo předpisy a služby vyžadující zámky zbraní nebo jiné kontroly střelných zbraní, ale že některé státy nebo základny mají svá vlastní omezení.\n",
    "Rozhodl se však podstoupit test na detektoru lži, aby vyvrátil veškeré spekulace, že to byl on, kdo poslal tweet sobě, uvedla jeho právnička Megan Kieferová. Za Dunlapa zatím nebyla podána žaloba, ale podle WWL-TV ve svém prohlášení uvedl, že jedna přijde.\n",
    "Minulý týden ministr obrany Mark Esper řekl, že více vojáků bude rozmístěno na Blízkém východě jako \"obranné\" opatření, které pomůže chránit před útoky z Íránu.\n",
    "Vypadá to, že Spider-Mana čeká svým způsobem návrat domů, když už Disney a Sony urovnaly své spory.\n",
    "Obvykle monzun na severu Indie ustupuje do začátku září, ale průměrný úhrn srážek v tomto měsíci byl 37% nad normálem. Bude-li situace pokračovat i ve zbývajících dnech, bude to podle odborníků z indického meteorologického oddělení zatím poslední monzun za několik desetiletí.\n",
    "Armáda vnímá frustrující trend jako bodnutí sebevraždy\n",
    "Pete Townshend vysvětlil divákům, co se děje: \"Zní to, jako by už nemohl dál, obávám se...\"\n",
    "Zdroje uvedly, že akce byla v souladu s projevem premiéra Naréndry Módího k národu z hradeb Červené pevnosti, když řekl, že některé černé ovce v daňové správě mohly zneužít své pravomoci a obtěžovat daňové poplatníky, a to buď tím, že se zaměřovaly na poctivé posudky, nebo podnikly nepřiměřené kroky za drobné či procesní porušení.\n",
    "V mnoha oblastech země stále nebývale prší, poslední je město Pune v západní Indii, kde přívalový déšť ve středu a ve čtvrtek způsobil několik úmrtí a spoušť ze zřícených budov.\n",
    "Seth Dunlap Louisiana: Moderátor WWL Radio vyhrožující žalobou kvůli anti-gay tweetu poslal tweet sám, stanice tvrdí, podobné případu Jussie Smollettové\n",
    "„O ceny pro vysokoškoláky svedou nelítostný boj tisíce studentů po celém světě a je velkým odrazem kvality našich studentů a vzdělání, kterého se jim zde dostává, že Dundee je tak silně zastoupen mezi oceněnými.\n",
    "Dodal, že USA poskytnou Organizaci pro zákaz chemických zbraní dalších 4,5 milionu dolarů na financování vyšetřování dalších případů podezřelých ze syrského použití chemických zbraní.\n",
    "Když se Townsend vrátil, řekl: \"Je mi to opravdu, opravdu líto. Roger teď nemůže mluvit.\n",
    "Dosud nepojmenovaný film bude uveden do kin 16. července 2021 a podle tiskové zprávy zaslané oběma studiemi jej bude produkovat studio Marvel Studios patřící společnosti Disney a jeho prezident Kevin Feige.\n",
    "\"Naše počty se nepohybují správným směrem,\" řekla Elizabeth Van Winkleová, ředitelka úřadu odolnosti sil v Pentagonu. Řekla, že většina vojenských tarifů je srovnatelná s civilisty, ale dodala: \"To není moc utěšující.\"\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "assert len(tgts_cubitt) == len(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: put tokenization_small100.py in path\n",
    "from transformers import M2M100ForConditionalGeneration\n",
    "from tokenization_small100 import SMALL100Tokenizer\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"alirezamsh/small100\")\n",
    "tokenizer = SMALL100Tokenizer.from_pretrained(\"alirezamsh/small100\", tgt_lang=\"cs\")\n",
    "\n",
    "tgts_m100 = []\n",
    "for line in srcs:\n",
    "    encoded = tokenizer(line, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(**encoded)\n",
    "    line_tgt = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    assert len(line_tgt) == 1\n",
    "    tgts_m100.append(line_tgt[0])\n",
    "    print(line_tgt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(srcs, tgts, ref_map):\n",
    "    refs = [ref_map[line] for line in srcs]\n",
    "    batched = [\n",
    "        {\"ref\": line[2], \"src\": line[0], \"mt\": line[1]}\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    scores = model.predict(batched, gpus=0, batch_size=10)[\"scores\"]\n",
    "    return np.array(scores)\n",
    "\n",
    "comet_google_n1 = get_scores(srcs, tgts_google, src_v_n1)\n",
    "comet_google_p1 = get_scores(srcs, tgts_google, src_v_p1)\n",
    "comet_google_p3 = get_scores(srcs, tgts_google, src_v_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "model_chrf = load(\"chrf\")\n",
    "\n",
    "def get_scores(srcs, tgts, ref_map):\n",
    "    refs = [ref_map[line] for line in srcs]\n",
    "    scores = [\n",
    "        model_chrf.compute(predictions=[line[1]], references=[[line[2]]])[\"score\"]\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def get_scores_all(srcs, tgts, ref_maps):\n",
    "    refs = [[ref_map[line] for ref_map in ref_maps] for line in srcs]\n",
    "    scores = [\n",
    "        model_chrf.compute(predictions=[line[1]], references=[line[2]])[\"score\"]\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "chrf_google_n1 = get_scores(srcs, tgts_google, src_v_n1)\n",
    "chrf_google_p1 = get_scores(srcs, tgts_google, src_v_p1)\n",
    "chrf_google_p3 = get_scores(srcs, tgts_google, src_v_p3)\n",
    "chrf_google_mix = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_p3])\n",
    "chrf_google_mixwpe = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_n1_pe, src_v_p1_pe, src_v_p3, src_v_p3_pe])\n",
    "chrf_google_mixwpenop3 = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_n1_pe, src_v_p1_pe])\n",
    "chrf_google_mixnop3 = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "model_bleu = load(\"sacrebleu\")\n",
    "\n",
    "def get_scores(srcs, tgts, ref_map):\n",
    "    refs = [ref_map[line] for line in srcs]\n",
    "    scores = [\n",
    "        model_bleu.compute(predictions=[line[1]], references=[[line[2]]])[\"score\"]\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    return np.array(scores)\n",
    "\n",
    "def get_scores_all(srcs, tgts, ref_maps):\n",
    "    refs = [[ref_map[line] for ref_map in ref_maps] for line in srcs]\n",
    "    scores = [\n",
    "        model_bleu.compute(predictions=[line[1]], references=[line[2]])[\"score\"]\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "\n",
    "bleu_google_n1 = get_scores(srcs, tgts_google, src_v_n1)\n",
    "bleu_google_p1 = get_scores(srcs, tgts_google, src_v_p1)\n",
    "bleu_google_p3 = get_scores(srcs, tgts_google, src_v_p3)\n",
    "bleu_google_mix = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_p3])\n",
    "bleu_google_mixwpe = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_n1_pe, src_v_p1_pe, src_v_p3, src_v_p3_pe])\n",
    "bleu_google_mixwpenop3 = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_n1_pe, src_v_p1_pe])\n",
    "bleu_google_mixnop3 = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "model_bleu = load(\"ter\")\n",
    "\n",
    "def get_scores(srcs, tgts, ref_map):\n",
    "    refs = [ref_map[line] for line in srcs]\n",
    "    scores = [\n",
    "        model_bleu.compute(predictions=[line[1]], references=[[line[2]]])[\"score\"]\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    return np.array(scores)\n",
    "\n",
    "def get_scores_all(srcs, tgts, ref_maps):\n",
    "    refs = [[ref_map[line] for ref_map in ref_maps] for line in srcs]\n",
    "    scores = [\n",
    "        model_bleu.compute(predictions=[line[1]], references=[line[2]])[\"score\"]\n",
    "        for line in zip(srcs, tgts, refs)\n",
    "    ]\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "ter_google_n1 = get_scores(srcs, tgts_google, src_v_n1)\n",
    "ter_google_p1 = get_scores(srcs, tgts_google, src_v_p1)\n",
    "ter_google_p3 = get_scores(srcs, tgts_google, src_v_p3)\n",
    "ter_google_mix = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_p3])\n",
    "ter_google_mixwpe = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_n1_pe, src_v_p1_pe, src_v_p3, src_v_p3_pe])\n",
    "ter_google_mixwpenop3 = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1, src_v_n1_pe, src_v_p1_pe])\n",
    "ter_google_mixnop3 = get_scores_all(srcs, tgts_google, [src_v_n1, src_v_p1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fig_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(\n",
    "    comet_cubitt_n1, comet_google_n1,\n",
    "    label=\"N1\",\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    comet_cubitt_p3, comet_google_p3,\n",
    "    label=\"P3\",\n",
    ")\n",
    "plt.xlim(0.5, 1)\n",
    "plt.ylim(0.5, 1)\n",
    "plt.plot(\n",
    "    [0, 1], [0, 1], color=\"black\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"COMET-DA scores\")\n",
    "plt.ylabel(\"CUBITT\")\n",
    "plt.xlabel(\"Google\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "ax1 = plt.subplot(3, 1, 1)\n",
    "plt.title(\"Distribution of COMET-DA with N1\")\n",
    "ax2 = plt.subplot(3, 1, 2, sharex=ax1, sharey=ax1)\n",
    "ax3 = plt.subplot(3, 1, 3, sharex=ax1, sharey=ax1)\n",
    "\n",
    "ax1.hist(comet_cubitt_n1, alpha=0.9)\n",
    "ax1.set_ylabel(\"CUBITT\")\n",
    "ax2.hist(comet_google_n1, alpha=0.9)\n",
    "ax2.set_ylabel(\"Google\")\n",
    "ax3.hist(comet_m100_n1, alpha=0.9)\n",
    "ax3.set_ylabel(\"M100\")\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def corr_nice(a, b):\n",
    "    return f\"{pearsonr(a, b)[0]:.2f}\"\n",
    "\n",
    "\n",
    "def print_table(source_txt, scores_comet, scores_bleu, scores_chrf, scores_ter, scores_human):\n",
    "    print(f\"Computed with {source_txt} as references\")\n",
    "    print(\n",
    "        \"Metric\", \"COMET-DA\", \"Human\",\n",
    "        sep=\" | \"\n",
    "    )\n",
    "    print(\n",
    "        \"-\", \"-\", \"-\",\n",
    "        sep=\"|\"\n",
    "    )\n",
    "    print(\n",
    "        \"ChrF\",\n",
    "        corr_nice(scores_comet, scores_chrf),\n",
    "        corr_nice(scores_human, scores_chrf),\n",
    "        sep=\" | \"\n",
    "    )\n",
    "    print(\n",
    "        \"BLEU\",\n",
    "        corr_nice(scores_comet, scores_bleu),\n",
    "        corr_nice(scores_human, scores_bleu),\n",
    "        sep=\" | \"\n",
    "    )\n",
    "    print(\n",
    "        \"TER\",\n",
    "        corr_nice(scores_comet, scores_ter),\n",
    "        corr_nice(scores_human, scores_ter),\n",
    "        sep=\" | \"\n",
    "    )\n",
    "    print(\n",
    "        \"COMET-DA\",\n",
    "        corr_nice(scores_comet, scores_comet),\n",
    "        corr_nice(scores_human, scores_comet),\n",
    "        sep=\" | \"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "# print_table(scores_google_n1_pe, bleu_google_n1_pe, chrf_google_n1_pe, ter_google_n1_pe)\n",
    "print_table(\"N1\", comet_google_n1, bleu_google_n1, chrf_google_n1, ter_google_n1, human_google)\n",
    "print_table(\"P1\", comet_google_p1, bleu_google_p1, chrf_google_p1, ter_google_p1, human_google)\n",
    "print_table(\"P3\", comet_google_p3, bleu_google_p3, chrf_google_p3, ter_google_p3, human_google)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def corr_nice(a, b):\n",
    "    return kendalltau(a, b)[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 2.5))\n",
    "XTICKLABELS = [\"ChrF\", \"BLEU\", \"TER\", \"COMET\"]\n",
    "def plot_corr(source_txt, offset_x, scores_comet, scores_bleu, scores_chrf, scores_ter, scores_human):\n",
    "    plt.xticks(range(len(XTICKLABELS)), XTICKLABELS)\n",
    "    plt.bar(\n",
    "       np.array(range(len(XTICKLABELS)))+offset_x,\n",
    "       [\n",
    "          corr_nice(scores_human, scores_chrf),\n",
    "          corr_nice(scores_human, scores_bleu),\n",
    "          corr_nice(scores_human, scores_ter),\n",
    "          corr_nice(scores_human, scores_comet),\n",
    "       ],\n",
    "       width=0.3,\n",
    "       label=source_txt\n",
    "    )\n",
    "    plt.ylim(None, 0.48)\n",
    "    plt.ylabel(\"$\\\\tau$ with Human\")\n",
    "    \n",
    "plot_corr(\"N1\", -0.3, comet_google_n1, bleu_google_n1, chrf_google_n1, ter_google_n1, human_google)\n",
    "plot_corr(\"P1\", -0.0, comet_google_p1, bleu_google_p1, chrf_google_p1, ter_google_p1, human_google)\n",
    "plot_corr(\"P3\", +0.3, comet_google_p3, bleu_google_p3, chrf_google_p3, ter_google_p3, human_google)\n",
    "\n",
    "plt.legend(\n",
    "    ncol=3, fancybox=False, edgecolor=\"black\",\n",
    "    handletextpad=0.1, columnspacing=1,\n",
    "    bbox_to_anchor=(1, 1.25),\n",
    "    loc=\"upper right\"\n",
    ").get_frame().set_linewidth(1.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure_single.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 2.9))\n",
    "XTICKLABELS = [\"ChrF\", \"BLEU\", \"TER\"]\n",
    "def plot_corr(source_txt, offset_x, scores_bleu, scores_chrf, scores_ter, scores_human):\n",
    "    plt.xticks(range(len(XTICKLABELS)), XTICKLABELS)\n",
    "    plt.bar(\n",
    "       np.array(range(len(XTICKLABELS)))+offset_x,\n",
    "       [\n",
    "          corr_nice(scores_human, scores_chrf),\n",
    "          corr_nice(scores_human, scores_bleu),\n",
    "          corr_nice(scores_human, scores_ter),\n",
    "       ],\n",
    "       width=0.2,\n",
    "       label=source_txt\n",
    "    )\n",
    "    plt.ylim(None, 0.48)\n",
    "    plt.ylabel(\"$\\\\rho$ with Human\")\n",
    "\n",
    "plot_corr(\"N1 P1\", -0.3, bleu_google_mixnop3, chrf_google_mixnop3, ter_google_mixnop3, human_google)\n",
    "plot_corr(\"N1 P1 N1' P1'\", -0.1, bleu_google_mixwpenop3, chrf_google_mixwpenop3, ter_google_mixwpenop3, human_google)\n",
    "plot_corr(\"N1 P1 P3\", +0.1, bleu_google_mix, chrf_google_mix, ter_google_mix, human_google)\n",
    "plot_corr(\"N1 P1 P3 N1' P1' P3'\", +0.3, bleu_google_mixwpe, chrf_google_mixwpe, ter_google_mixwpe, human_google)\n",
    "\n",
    "plt.legend(\n",
    "    ncol=2, fancybox=False, edgecolor=\"black\",\n",
    "    handletextpad=0.1, columnspacing=1,\n",
    "    bbox_to_anchor=(1, 1.4),\n",
    "    loc=\"upper right\"\n",
    ").get_frame().set_linewidth(1.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure_mixed.pdf\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
